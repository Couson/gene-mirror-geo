{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import gzip\n",
    "from ftplib import FTP\n",
    "# from bs4 import BeautifulSoup\n",
    "# import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # ftp.close()\n",
    "# ftp = FTP('ftp.1000genomes.ebi.ac.uk')\n",
    "# ftp.login()\n",
    "# print(ftp.nlst())\n",
    "# # path to FASTQ\n",
    "# ftp.cwd('vol1/ftp/phase3/data/HG00096/sequence_read')\n",
    "# # ftp.cwd('data_collections')\n",
    "# file_lst = ftp.nlst()\n",
    "# file_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# donwload(file_lst[0], ftp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ftp = FTP('ftp.1000genomes.ebi.ac.uk')\n",
    "# ftp.login()\n",
    "# # path to BAM\n",
    "# ftp.cwd('vol1/ftp/phase3/data/HG00096/alignment')\n",
    "# # ftp.cwd('data_collections')\n",
    "# ftp.nlst()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ftp = FTP('ftp.1000genomes.ebi.ac.uk')\n",
    "# # ftp.login()\n",
    "# # ftp.cwd('vol1/ftp/release/20130502')\n",
    "# # vcf_files = ftp.nlst()\n",
    "\n",
    "# # # only keep vcf.gz / vcf.gz.tbi\n",
    "# # vcf_files = [i for i in vcf_files if (i[-3:] == '.gz')]\n",
    "# # vcf_files\n",
    "\n",
    "# ftp = FTP('ftp.1000genomes.ebi.ac.uk')\n",
    "# ftp.login()\n",
    "# # path to BAM\n",
    "# ftp.cwd('vol1/ftp/phase3/data/HG00096/alignment')\n",
    "# # ftp.cwd('data_collections')\n",
    "# all_files = ftp.nlst()\n",
    "# bam_files = [i for i in all_files if (i[-4:] == '.bam')]\n",
    "# bam_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ftp.retrlines('LIST')\n",
    "# ftp.dir()\n",
    "# ftp.nlst()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = json.load(open('data-params.json'))\n",
    "# cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def unzip_gz(path):\n",
    "#     import gzip\n",
    "#     for l in gzip.open(path, 'rt'):\n",
    "#         yield eval(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vcf(chromosome, ftp, out_path):\n",
    "    '''\n",
    "    chromosome: list of chromosomes needed eg.\n",
    "    ftp: ftp ojject from the parent func\n",
    "    '''\n",
    "    ### chr*\n",
    "    ### TODO: clean chromosome format\n",
    "    VCF_SITE = 'vol1/ftp/release/20130502'\n",
    "    CHR_IDX = 1\n",
    "    VCF_EXT = '.vcf.gz'\n",
    "    VCF_IDX = - len(VCF_EXT)\n",
    "    \n",
    "    ftp.cwd(VCF_SITE)\n",
    "    all_files = ftp.nlst()\n",
    "    # chr* is at the 2nd index place\n",
    "    # only keep .vcf.gz\n",
    "    vcf_files = [i for i in all_files if (i[VCF_IDX:] == VCF_EXT)\\\n",
    "                 and (i.split('.')[CHR_IDX] in chromosome)]\n",
    "     \n",
    "    out_path = os.path.join(out_path, 'vcf')\n",
    "    if not (os.path.exists(out_path)):\n",
    "        os.mkdir(out_path)\n",
    "    \n",
    "    donwload(vcf_files, ftp, out_path)\n",
    "    \n",
    "    return vcf_files\n",
    "\n",
    "def get_bam(sample, ftp, out_path):\n",
    "    '''\n",
    "    sample: list of samples eg. HG00096\n",
    "    chromosome: list of chromosomes needed \n",
    "    ftp: ftp ojject from the parent func\n",
    "    '''\n",
    "    ### chrom*\n",
    "    BAM_EXT = '.bam'\n",
    "    BAM_IDX = -len(BAM_EXT)\n",
    "    ftp.cwd('vol1/ftp/phase3/data')\n",
    "#     print(ftp.nlst())\n",
    "    out = []\n",
    "    for sam in sample:\n",
    "        BAM_SITE = '%s/alignment' % sam\n",
    "        \n",
    "        ftp.cwd(BAM_SITE)\n",
    "        all_files = ftp.nlst()\n",
    "        bam_files = [i for i in all_files if (i[BAM_IDX:] == BAM_EXT)]\n",
    "        \n",
    "        out_path = os.path.join(out_path, 'bam')\n",
    "        if not (os.path.exists(out_path)):\n",
    "            os.mkdir(out_path)\n",
    "        \n",
    "        donwload(bam_files, ftp, out_path)\n",
    "        \n",
    "        out += bam_files\n",
    "        ftp.cwd('../../')\n",
    "        \n",
    "    return out\n",
    "\n",
    "def get_fastq(sample, ftp, out_path):\n",
    "    '''\n",
    "    ### NO CRHOMOSOME FORMAT\n",
    "    sample: list of samples eg. HG00096\n",
    "    chromosome: list of chromosomes needed\n",
    "    ftp: ftp ojject from the parent func\n",
    "    '''\n",
    "    FASTQ_EXT = '.fastq.gz'\n",
    "    FASTQ_IDX = - len(FASTQ_EXT)\n",
    "    ftp.cwd('vol1/ftp/phase3/data/')\n",
    "#     print(ftp.nlst())\n",
    "    out = []\n",
    "    for sam in sample:\n",
    "        FASTQ_SITE = '%s/sequence_read' % sam\n",
    "        ftp.cwd(FASTQ_SITE)\n",
    "        all_files = ftp.nlst()\n",
    "        fastq_files = [i for i in all_files if (i[FASTQ_IDX:] == FASTQ_EXT)]\n",
    "        \n",
    "        out_path = os.path.join(out_path, 'fastq')\n",
    "        if not (os.path.exists(out_path)):\n",
    "            os.mkdir(out_path)\n",
    "        donwload(fastq_files, ftp, out_path)\n",
    "        \n",
    "        out += fastq_files\n",
    "        ftp.cwd('../../')\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alignment bam phase1/data/HG00096/\n",
    "# 'phase3/data/HG00100/sequence_read'\n",
    "\n",
    "\n",
    "def get_data_list(sample, chromosome, file_format, out_path):\n",
    "    '''\n",
    "    file_format either be VCF/BAM/FASTQ\n",
    "    '''\n",
    "    SITE = 'ftp.1000genomes.ebi.ac.uk'\n",
    "\n",
    "    ftp = FTP(SITE)\n",
    "    ftp.login()\n",
    "    for i in file_format:\n",
    "        if 'VCF' == i:\n",
    "            yield get_vcf(chromosome, ftp, out_path)\n",
    "            ftp.cwd('../../../../')\n",
    "            \n",
    "        elif 'BAM' == i:\n",
    "            ### TODO determine sample\n",
    "            yield get_bam(sample, ftp, out_path)\n",
    "            ftp.cwd('../../../../')\n",
    "\n",
    "        elif 'FASTQ' == i:\n",
    "            ### TODO determine sample\n",
    "            yield get_fastq(sample, ftp, out_path)\n",
    "            ftp.cwd('../../../../')\n",
    "            \n",
    "#     get_data_list(sample, chromosome, file_format, out_path)\n",
    "    \n",
    "    ftp.quit()\n",
    "    ftp.close()\n",
    "\n",
    "\n",
    "def donwload(file_lst, ftp, out_path):\n",
    "    '''\n",
    "    use this funcs at the lst dir\n",
    "    '''\n",
    "    for file in file_lst:\n",
    "        write_path = os.path.join(out_path, file)\n",
    "        if os.path.exists(write_path):\n",
    "            print('aready exists' + file)\n",
    "            continue\n",
    "        print('downloading %s' % file)\n",
    "        with open(write_path, 'wb') as fh:\n",
    "            ftp.retrbinary('RETR %s' % file, fh.write)\n",
    "        print('finish downloading %s' % file)\n",
    "#     ftp.cwd('../../')\n",
    "\n",
    "def get_data(**cfg):\n",
    "    '''\n",
    "    reads in the desired data in data-params.json \n",
    "    and uses the configuration to download all the tables\n",
    "    cfg = json.load(open('data-params.json'))\n",
    "    '''\n",
    "    \n",
    "    sample = cfg['sample']\n",
    "    chrom = cfg['chromosome']\n",
    "    file_type = cfg['format']\n",
    "    ###########\n",
    "    out_path = os.path.join('..', cfg['outpath'])\n",
    "    \n",
    "    if not (os.path.exists(out_path)):\n",
    "        os.mkdir(out_path)\n",
    "    \n",
    "    return get_data_list(sample, chrom, file_type, out_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample': ['HG00096', 'HG00100'],\n",
       " 'chromosome': ['chr2'],\n",
       " 'format': ['VCF'],\n",
       " 'outpath': 'data/raw'}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = json.load(open('../config/data-params.json'))\n",
    "cfg['chromosome'] = ['chr%s' % s for s in range(1, 23)]\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in get_data(**cfg):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in get_data_list(['HG00096'], ['chr22'],\n",
    "#               ['FASTQ']):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bcftools concat data/interim/chr1_filtered.vcf data/interim/chr2_filtered.vcf data/interim/chr3_filtered.vcf data/interim/chr4_filtered.vcf data/interim/chr5_filtered.vcf data/interim/chr6_filtered.vcf data/interim/chr7_filtered.vcf data/interim/chr8_filtered.vcf data/interim/chr9_filtered.vcf data/interim/chr10_filtered.vcf data/interim/chr11_filtered.vcf data/interim/chr12_filtered.vcf data/interim/chr13_filtered.vcf data/interim/chr14_filtered.vcf data/interim/chr15_filtered.vcf data/interim/chr16_filtered.vcf data/interim/chr17_filtered.vcf data/interim/chr18_filtered.vcf data/interim/chr19_filtered.vcf data/interim/chr20_filtered.vcf data/interim/chr21_filtered.vcf data/interim/chr22_filtered.vcf -o data/interim/merged.vcf \n"
     ]
    }
   ],
   "source": [
    "import shlex\n",
    "import subprocess as sp\n",
    "def merge_vcf(**cfg):\n",
    "    lines = ''\n",
    "    for k, v in cfg['bcftools'].items():\n",
    "        if isinstance(v, list):\n",
    "            line = k + ' ' + ' '.join(v)\n",
    "        elif k == 'concat':\n",
    "            line = k + ' ' + ' '.join(\n",
    "                [v.replace('*', 'chr' + str(l)) for l in range(1, 23)]\n",
    "            ) \n",
    "        else:\n",
    "            line = k + ' ' + v\n",
    "        lines += line + ' '\n",
    "    cmd = \"bcftools \" + lines\n",
    "    print(cmd)\n",
    "#     cmd_lst = shlex.split(cmd)\n",
    "#     proc = sp.call(cmd_lst)\n",
    "\n",
    "\n",
    "\n",
    "def filter_vcf(**cfg):\n",
    "    lines = ''\n",
    "    for k, v in cfg['plink2'].items():\n",
    "        if isinstance(v, list):\n",
    "            line = k + ' ' + ' '.join(v)\n",
    "        else:\n",
    "            line = k + ' ' + v\n",
    "        lines += line + ' '\n",
    "    \n",
    "    for idx in range(1, 23):\n",
    "        s = 'chr' + str(idx)\n",
    "        cmd = (\"plink2 \" + lines).replace('*', s)\n",
    "        print(cmd)\n",
    "#         cmd_lst = shlex.split(cmd)\n",
    "#         proc = sp.call(cmd_lst)\n",
    "\n",
    "cfg = json.load(open('../config/pipeline.json')) \n",
    "merge_vcf(**cfg)\n",
    "# cfg = json.load(open('../config/pipeline.json'))\n",
    "# filter_vcf(**cfg)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plink2 --vcf  ALL.chr1.shapeit2_integrated_v1a.GRCh38.20181129.phased.vcf.gz --snps-only --maf 0.05 --geno 0.1  --mind 0.05  --recode vcf --out test\n",
    "\n",
    "# ####### helper method for fastq2vcf ######\n",
    "# def fastq2bam(**cfg):\n",
    "#     lines = ''\n",
    "#     for k, v in cfg['fastq2bam'].items():\n",
    "#         if isinstance(v, list):\n",
    "#             line = k + ' ' + ' '.join(v)\n",
    "#         else:\n",
    "#             line = k + ' ' + v\n",
    "#         lines += line + ' '\n",
    "\n",
    "        \n",
    "        \n",
    "# def bam2vcf(**cfg):\n",
    "#     lines = ''\n",
    "#     for k, v in cfg['bam2vcf'].items():\n",
    "#         if isinstance(v, list):\n",
    "#             line = k + ' ' + ' '.join(v)\n",
    "#         else:\n",
    "#             line = k + ' ' + v\n",
    "#         lines += line + ' '\n",
    "# ############ end of helper method ########\n",
    "\n",
    "# def fastq2vcf(**cfg):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import shlex\n",
    "import sys\n",
    "import subprocess as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_pruning(**proc_cfg):\n",
    "    import shlex\n",
    "    import subprocess as sp\n",
    "    \n",
    "    lines = ''\n",
    "    for k, v in proc_cfg['pca_pruning'].items():\n",
    "        line = k + ' ' + v\n",
    "        lines += line + ' '\n",
    "    cmd = 'plink2 ' + lines\n",
    "#     print(cmd)\n",
    "    #####\n",
    "#     cmd_lst = shlex.split(cmd)\n",
    "#     proc = sp.Popen(cmd_lst, stdout=sp.PIPE, stderr=sp.PIPE)\n",
    "    #####\n",
    "    return cmd\n",
    "\n",
    "def pca_conduct(**proc_cfg):\n",
    "    import shlex\n",
    "    import subprocess as sp\n",
    "\n",
    "    lines = ''\n",
    "    for k, v in proc_cfg['pca_conduct'].items():\n",
    "        line = k + ' ' + v\n",
    "        lines += line + ' '\n",
    "    cmd = 'plink2 ' + lines\n",
    "#     print(cmd)\n",
    "    #####\n",
    "#     cmd_lst = shlex.split(cmd)\n",
    "#     proc = sp.Popen(cmd_lst, stdout=sp.PIPE, stderr=sp.PIPE)\n",
    "    #####\n",
    "    return cmd\n",
    "\n",
    "def plot_pca():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from matplotlib import pyplot as plt\n",
    "    # will make it generic as development\n",
    "    val_path = '../data/interim/pca.eigenval'\n",
    "    vec_path = '../data/interim/pca.eigenvec'\n",
    "\n",
    "    vec = pd.read_csv(vec_path, header = None, sep = \" \")\n",
    "    val = pd.read_csv(val_path, header = None, sep = \" \")\n",
    "    vec = vec.loc[:, 1:].set_index(1)\n",
    "\n",
    "    plt.scatter(x = vec.loc[:, 2], y = vec.loc[:, 3], color = 'r', marker = '.')\n",
    "    plt.title('PCA of 2 PC')\n",
    "    plt.xlabel('1st PC')\n",
    "    plt.ylabel('2nd PC')\n",
    "    \n",
    "    plt.savefig('pca_plot')\n",
    "    \n",
    "def process_data(**proc_cfg):\n",
    "    pca_pruning(**proc_cfg);\n",
    "    pca_conduct(**proc_cfg);\n",
    "    \n",
    "    # will need to take in/out path\n",
    "    plot_pca();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plink2 --vcf data/interim/merged.vcf --double-id  --allow-extra-chr  --set-missing-var-ids @:# --indep-pairwise 50 10 0.1 --out data/interim/pca \n",
      "plink2 --vcf data/interim/merged.vcf --double-id  --allow-extra-chr  --set-missing-var-ids @:# --extract data/interim/pca.prune.in --make-bed  --pca  --out data/interim/pca \n"
     ]
    }
   ],
   "source": [
    "proc_cfg = json.load(open('../config/process-params.json'))\n",
    "proc_cfg\n",
    "print(pca_pruning(**proc_cfg))\n",
    "print(pca_conduct(**proc_cfg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plink2 --vcf ../data/test/chr22_test.vcf.gz --double-id  --allow-extra-chr  --set-missing-var-ids @:# --extract ../data/interim/pca.prune.in --make-bed  --pca  --out ../data/interim/pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmd = 'python --version'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmd_lst = shlex.split(cmd)\n",
    "# cmd_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sp.call(cmd_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proc = sp.Popen(cmd_lst, stdout=sp.PIPE, stderr=sp.PIPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proc.stdout.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.path.join('..', 'data/raw', 'file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
